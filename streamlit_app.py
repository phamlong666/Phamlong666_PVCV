import streamlit as st
import requests
import uuid

# H√†m ƒë·ªçc n·ªôi dung t·ª´ file vƒÉn b·∫£n
def rfile(name_file):
    try:
        with open(name_file, "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
            st.error(f"File {name_file} kh√¥ng t·ªìn t·∫°i.")



# Constants
WEBHOOK_URL = rfile("WEBHOOK_URL.txt").strip()
BEARER_TOKEN = st.secrets.get("BEARER_TOKEN")

def generate_session_id():
    return str(uuid.uuid4())

def send_message_to_llm(session_id, message):
    headers = {
        "Authorization": f"Bearer {BEARER_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {
        "sessionId": session_id,
        "chatInput": message
    }
    try:
        response = requests.post(WEBHOOK_URL, json=payload, headers=headers, timeout=10)
        response.raise_for_status()
        return response.json().get("output", "No output received")
    except requests.exceptions.RequestException as e:
        return f"Error: Failed to connect to the LLM - {str(e)}"

def main():
    # Hi·ªÉn th·ªã logo (n·∫øu c√≥)
    try:
        col1, col2, col3 = st.columns([3, 2, 3])
        with col2:
            st.image("logo.png")
    except:
        pass
    # Hi·ªÉn th·ªã ti√™u ƒë·ªÅ


    title_content = rfile("00.xinchao.txt")
    print ("title_content",title_content)
    st.markdown(
        f"""<h1 style="text-align: center; font-size: 24px;">{title_content}</h1>""",
        unsafe_allow_html=True
    )

    # Kh·ªüi t·∫°o session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "session_id" not in st.session_state:
        st.session_state.session_id = generate_session_id()

    # CSS ƒë·ªÉ cƒÉn ch·ªânh tr·ª£ l√Ω b√™n tr√°i, ng∆∞·ªùi h·ªèi b√™n ph·∫£i, v√† th√™m icon tr·ª£ l√Ω
    st.markdown(
        """
        <style>
            .assistant {
                padding: 10px;
                border-radius: 10px;
                max-width: 75%;
                background: none; /* M√†u trong su·ªët */
                text-align: left;
            }
            .user {
                padding: 10px;
                border-radius: 10px;
                max-width: 75%;
                background: none; /* M√†u trong su·ªët */
                text-align: right;
                margin-left: auto;
            }
            .assistant::before { content: "ü§ñ "; font-weight: bold; }
        </style>
        """,
        unsafe_allow_html=True
    )

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ tin nh·∫Øn
    for message in st.session_state.messages:
        if message["role"] == "assistant":
            st.markdown(f'<div class="assistant">{message["content"]}</div>', unsafe_allow_html=True)
        elif message["role"] == "user":
            st.markdown(f'<div class="user">{message["content"]}</div>', unsafe_allow_html=True)

    # √î nh·∫≠p li·ªáu cho ng∆∞·ªùi d√πng
    if prompt := st.chat_input("Nh·∫≠p n·ªôi dung c·∫ßn trao ƒë·ªïi ·ªü ƒë√¢y nh√©?"):
        # L∆∞u tin nh·∫Øn ng∆∞·ªùi d√πng
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.markdown(f'<div class="user">{prompt}</div>', unsafe_allow_html=True)

        # G·ª≠i y√™u c·∫ßu ƒë·∫øn LLM v√† nh·∫≠n ph·∫£n h·ªìi
        with st.spinner("ƒêang ch·ªù ph·∫£n h·ªìi t·ª´ AI..."):
            llm_response = send_message_to_llm(st.session_state.session_id, prompt)

        # Hi·ªÉn th·ªã v√† l∆∞u ph·∫£n h·ªìi c·ªßa tr·ª£ l√Ω
        st.markdown(f'<div class="assistant">{llm_response}</div>', unsafe_allow_html=True)
        st.session_state.messages.append({"role": "assistant", "content": llm_response})

if __name__ == "__main__":
    main()